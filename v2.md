# Dodge Docker's Rate Limits: Setting Up Registry Proxies with Terraform

## Situation üö®

In early 2025, Docker Hub announced a significant change: free users would be limited to just 10 image pulls per hour starting April 1st. This wasn't an April Fool's joke but a real constraint affecting developers worldwide.

Around the same time, Upbound revealed that free users could only pull the latest Crossplane package versions as of March 25th, preventing access to specific older versions that many workflows depend on.

For our Kubernetes-based environments with frequent scaling and spot instances, these policies spelled serious trouble. Our quick calculations showed clients would hit those limits almost immediately during normal operations:

- A cluster with 5 nodes that needs to pull 20 images each = 100 pulls
- Node replacements due to spot instance recycling = random ammount of additional pulls
- GitLab CI/CD pipelines running tests on Kubernetes runners = additional pulls against the quota

While Docker Hub hadn't yet enforced their policy, it felt like just a matter of time before our infrastructure would face serious disruption.

## Task üéØ

We needed to solve multiple critical challenges:

1. Bypass the new restrictive rate limits from Docker Hub
2. Ensure continuous access to specific Crossplane package versions
3. Improve resilience against external registry outages
4. Implement a solution that would work across all of our clients' infrastructure

The solution needed to be transparent to our client applications and create minimal operational overhead.

## Action üõ†Ô∏è

We decided to build registry proxies that would allow us to cache both Docker images and Crossplane packages, eliminating both rate limits and preserving access to specific package versions.

### AWS ECR Pull-Through Cache

Amazon Elastic Container Registry's pull-through cache feature automatically fetches and stores images from upstream registries upon first request:

```terraform
# First, create a secret to store Docker Hub credentials
resource "aws_secretsmanager_secret" "docker_hub_creds" {
  name = "ecr-pullthroughcache/docker-hub"
}

# Store the Docker Hub username and access token
resource "aws_secretsmanager_secret_version" "docker_hub_creds_version" {
  secret_id     = aws_secretsmanager_secret.docker_hub_creds.id
  secret_string = jsonencode({
    username    = var.docker_hub_username
    accessToken = var.docker_hub_access_token
  })
}

# Create the pull-through cache rule
resource "aws_ecr_pull_through_cache_rule" "docker_hub" {
  ecr_repository_prefix = "docker-hub"
  upstream_registry_url = "registry-1.docker.io"
  credential_arn        = aws_secretsmanager_secret.docker_hub_creds.arn
}
```

### 2. Google Artifact Registry Proxy

Similarly, for Google Artifact Registry, we configured Google Cloud's Artifact Registry to create remote repositories that proxy Docker Hub:

```terraform
# Create a remote repository in Google Artifact Registry
resource "google_artifact_registry_repository" "docker_hub_proxy" {
  location      = var.region
  repository_id = "docker-hub-proxy"
  format        = "DOCKER"
  mode          = "REMOTE_REPOSITORY"

  # Configure the remote repository to point to Docker Hub
  remote_repository_config {
    description = "Docker Hub proxy"
    docker_repository {
      public_repository = "DOCKER_HUB"
    }
    # Add Docker Hub credentials for authenticated pulls
    upstream_credentials {
      username               = var.docker_hub_username
      password_secret_version = google_secret_manager_secret.docker_hub_token.id
    }
  }
}
```

### 3. Harbor Proxy


### 4. Updating Kubernetes Manifests

We updated our deployment templates to reference images through our proxies:

**AWS ECR format:**

```
account-id.dkr.ecr.region.amazonaws.com/docker-hub/nginx:latest
```

**Google Artifact Registry format:**

```
region-docker.pkg.dev/project-id/docker-hub-proxy/nginx:latest
```

**Harbor format:**

```
harbor.internal.example.com/dockerhub-proxy/nginx:latest
```

For Crossplane packages, we created similar proxies and updated our package references accordingly.

## Results ‚úÖ

Our registry proxy implementation delivered several important benefits:

1. **Rate limit immunity** - Kubernetes clusters now pull all images through our proxies, counting as just one pull against Docker Hub's quota regardless of how many nodes need the image.

2. **Preserved access to package versions** - We can maintain access to all Crossplane package versions we've previously used, making upgrades more controlled.

3. **Improved resilience** - Even during Docker Hub outages (which have happened several times this year), our infrastructure continues functioning normally.

4. **Performance improvements** - We observed 30-40% faster container startup times since images now pull from our local proxies.

5. **Better control** - We gained visibility into which images are actually being used across our environments.

The implementation required some upfront effort to configure correctly across our multi-cloud infrastructure, but now we sleep better knowing our clients' environments don't depend on external registry availability or rate limits!

This approach also gave us an unexpected benefit: we can now pre-warm image caches for critical services, further improving reliability during scaling events.

---

_This post was written by the Platform Engineering team at Entigo, building resilient infrastructure for modern applications._
